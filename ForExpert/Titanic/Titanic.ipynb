{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "i4cfy17Jc27z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "TqPmfsfkaMJE",
        "outputId": "98747764-4d1e-4ea2-be6c-3bb22ee8c789"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data=pd.read_csv('train.csv')\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "C6EyiA1ebZGl",
        "outputId": "1863eb81-78ee-4632-9c46-d7809e2cc930"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name  Sex   Age  SibSp  Parch  \\\n",
              "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
              "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
              "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
              "\n",
              "             Ticket     Fare Cabin  Embarked  \n",
              "0         A/5 21171   7.2500     0       0.0  \n",
              "1          PC 17599  71.2833   C85       1.0  \n",
              "2  STON/O2. 3101282   7.9250     0       0.0  \n",
              "3            113803  53.1000  C123       0.0  \n",
              "4            373450   8.0500     0       0.0  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data=train_data.replace(['female','male'],[0,1])\n",
        "train_data=train_data.replace(['S','C','Q'],[0,1,2])\n",
        "tarin_data=train_data.fillna(0,inplace=True)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2upJ21E8ckLI",
        "outputId": "ce37d12d-0a77-4813-d90a-4dc9b8307496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(891, 7) (891, 1)\n"
          ]
        }
      ],
      "source": [
        "Y_train=train_data[['Survived']]\n",
        "X_train=train_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "Y_train=np.array(Y_train)\n",
        "X_train=np.array(X_train)\n",
        "print(X_train.shape,Y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "E4mc9j2iyB0M",
        "outputId": "c431d9f7-d8fa-4d64-bf5f-72405b8de954"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
              "0       3    1  34.5      0      0   7.8292         2\n",
              "1       3    0  47.0      1      0   7.0000         0\n",
              "2       2    1  62.0      0      0   9.6875         2\n",
              "3       3    1  27.0      0      0   8.6625         0\n",
              "4       3    0  22.0      1      1  12.2875         0"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "test_data = test_data.replace(['female', 'male'], [0, 1])\n",
        "test_data = test_data.replace(['S', 'C', 'Q'], [0, 1, 2])\n",
        "test_data = test_data.fillna(0)\n",
        "X_test = test_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "test = pd.read_csv('gender_submission.csv')\n",
        "Y_test = test[['Survived']]\n",
        "\n",
        "X_test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIvvpMl-zpeu",
        "outputId": "5f72b3d0-d7d3-4792-a7c1-c24edd960ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(418, 7) (418, 1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(X_test.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(10).batch(8)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "3bZLGMNshziZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "model=tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Dense(6,activation='relu'),\n",
        "                                  tf.keras.layers.Dense(16,activation='relu'),\n",
        "                                  tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkeLT3uUxf_H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "X-YpixgMkvKU"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "             loss=tf.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mplSP_kjlhkY",
        "outputId": "c56b50a7-c2b7-4ebd-a854-a7775728ce74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(891, 7) (891, 1)\n",
            "(418, 7) (418, 1)\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 2s 2ms/step - loss: 2.7293 - accuracy: 0.4186\n",
            "Epoch 2/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 1.1738 - accuracy: 0.4456\n",
            "Epoch 3/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.6465\n",
            "Epoch 4/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6532\n",
            "Epoch 5/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6566\n",
            "Epoch 6/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6532\n",
            "Epoch 7/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6465\n",
            "Epoch 8/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6465\n",
            "Epoch 9/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6498\n",
            "Epoch 10/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.6498\n",
            "Epoch 11/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.6554\n",
            "Epoch 12/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6554\n",
            "Epoch 13/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6655\n",
            "Epoch 14/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.6712\n",
            "Epoch 15/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6723\n",
            "Epoch 16/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6768\n",
            "Epoch 17/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.6768\n",
            "Epoch 18/200\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.6813\n",
            "Epoch 19/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.6880\n",
            "Epoch 20/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.6914\n",
            "Epoch 21/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6835\n",
            "Epoch 22/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.6846\n",
            "Epoch 23/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.6857\n",
            "Epoch 24/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.6902\n",
            "Epoch 25/200\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.6880\n",
            "Epoch 26/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.6981\n",
            "Epoch 27/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.6981\n",
            "Epoch 28/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7082\n",
            "Epoch 29/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7093\n",
            "Epoch 30/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7037\n",
            "Epoch 31/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7093\n",
            "Epoch 32/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7093\n",
            "Epoch 33/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7026\n",
            "Epoch 34/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7116\n",
            "Epoch 35/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7127\n",
            "Epoch 36/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7104\n",
            "Epoch 37/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7127\n",
            "Epoch 38/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7160\n",
            "Epoch 39/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7149\n",
            "Epoch 40/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7183\n",
            "Epoch 41/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7138\n",
            "Epoch 42/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7172\n",
            "Epoch 43/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7183\n",
            "Epoch 44/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7250\n",
            "Epoch 45/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7183\n",
            "Epoch 46/200\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7172\n",
            "Epoch 47/200\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7284\n",
            "Epoch 48/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7183\n",
            "Epoch 49/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7329\n",
            "Epoch 50/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7262\n",
            "Epoch 51/200\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7250\n",
            "Epoch 52/200\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7250\n",
            "Epoch 53/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7318\n",
            "Epoch 54/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7340\n",
            "Epoch 55/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7273\n",
            "Epoch 56/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7351\n",
            "Epoch 57/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7340\n",
            "Epoch 58/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7396\n",
            "Epoch 59/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7385\n",
            "Epoch 60/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7419\n",
            "Epoch 61/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7553\n",
            "Epoch 62/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7520\n",
            "Epoch 63/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7598\n",
            "Epoch 64/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7542\n",
            "Epoch 65/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7508\n",
            "Epoch 66/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7520\n",
            "Epoch 67/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7565\n",
            "Epoch 68/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7565\n",
            "Epoch 69/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7632\n",
            "Epoch 70/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7598\n",
            "Epoch 71/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7609\n",
            "Epoch 72/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7587\n",
            "Epoch 73/200\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7598\n",
            "Epoch 74/200\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7598\n",
            "Epoch 75/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7587\n",
            "Epoch 76/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7632\n",
            "Epoch 77/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7565\n",
            "Epoch 78/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7587\n",
            "Epoch 79/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7643\n",
            "Epoch 80/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7632\n",
            "Epoch 81/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7632\n",
            "Epoch 82/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7699\n",
            "Epoch 83/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7621\n",
            "Epoch 84/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7755\n",
            "Epoch 85/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7643\n",
            "Epoch 86/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7733\n",
            "Epoch 87/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7666\n",
            "Epoch 88/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7733\n",
            "Epoch 89/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7688\n",
            "Epoch 90/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7654\n",
            "Epoch 91/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7677\n",
            "Epoch 92/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7565\n",
            "Epoch 93/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7710\n",
            "Epoch 94/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7699\n",
            "Epoch 95/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7699\n",
            "Epoch 96/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7688\n",
            "Epoch 97/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7688\n",
            "Epoch 98/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7654\n",
            "Epoch 99/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7632\n",
            "Epoch 100/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7666\n",
            "Epoch 101/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7621\n",
            "Epoch 102/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7733\n",
            "Epoch 103/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7722\n",
            "Epoch 104/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7710\n",
            "Epoch 105/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7710\n",
            "Epoch 106/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7621\n",
            "Epoch 107/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7755\n",
            "Epoch 108/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7778\n",
            "Epoch 109/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7677\n",
            "Epoch 110/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7778\n",
            "Epoch 111/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7643\n",
            "Epoch 112/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7654\n",
            "Epoch 113/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7710\n",
            "Epoch 114/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7654\n",
            "Epoch 115/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7755\n",
            "Epoch 116/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7722\n",
            "Epoch 117/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7722\n",
            "Epoch 118/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7699\n",
            "Epoch 119/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7710\n",
            "Epoch 120/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7688\n",
            "Epoch 121/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7677\n",
            "Epoch 122/200\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7778\n",
            "Epoch 123/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7744\n",
            "Epoch 124/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7632\n",
            "Epoch 125/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7699\n",
            "Epoch 126/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7722\n",
            "Epoch 127/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7778\n",
            "Epoch 128/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7744\n",
            "Epoch 129/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7699\n",
            "Epoch 130/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7778\n",
            "Epoch 131/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7733\n",
            "Epoch 132/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7710\n",
            "Epoch 133/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7710\n",
            "Epoch 134/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7722\n",
            "Epoch 135/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7688\n",
            "Epoch 136/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7744\n",
            "Epoch 137/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7722\n",
            "Epoch 138/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7800\n",
            "Epoch 139/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7632\n",
            "Epoch 140/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7778\n",
            "Epoch 141/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7800\n",
            "Epoch 142/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7778\n",
            "Epoch 143/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7778\n",
            "Epoch 144/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7755\n",
            "Epoch 145/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7688\n",
            "Epoch 146/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7699\n",
            "Epoch 147/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7733\n",
            "Epoch 148/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7699\n",
            "Epoch 149/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7767\n",
            "Epoch 150/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7755\n",
            "Epoch 151/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7811\n",
            "Epoch 152/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7834\n",
            "Epoch 153/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7811\n",
            "Epoch 154/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7778\n",
            "Epoch 155/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7845\n",
            "Epoch 156/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7834\n",
            "Epoch 157/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7868\n",
            "Epoch 158/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7834\n",
            "Epoch 159/200\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7845\n",
            "Epoch 160/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7800\n",
            "Epoch 161/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7868\n",
            "Epoch 162/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7856\n",
            "Epoch 163/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7879\n",
            "Epoch 164/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7935\n",
            "Epoch 165/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7912\n",
            "Epoch 166/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7879\n",
            "Epoch 167/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7946\n",
            "Epoch 168/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8002\n",
            "Epoch 169/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8070\n",
            "Epoch 170/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8081\n",
            "Epoch 171/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8025\n",
            "Epoch 172/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8047\n",
            "Epoch 173/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8148\n",
            "Epoch 174/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8148\n",
            "Epoch 175/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8238\n",
            "Epoch 176/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8126\n",
            "Epoch 177/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8148\n",
            "Epoch 178/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8103\n",
            "Epoch 179/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8148\n",
            "Epoch 180/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8260\n",
            "Epoch 181/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8249\n",
            "Epoch 182/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8193\n",
            "Epoch 183/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8204\n",
            "Epoch 184/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8182\n",
            "Epoch 185/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8193\n",
            "Epoch 186/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8215\n",
            "Epoch 187/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8171\n",
            "Epoch 188/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8171\n",
            "Epoch 189/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8193\n",
            "Epoch 190/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8227\n",
            "Epoch 191/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8215\n",
            "Epoch 192/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8249\n",
            "Epoch 193/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8272\n",
            "Epoch 194/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8182\n",
            "Epoch 195/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8272\n",
            "Epoch 196/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8272\n",
            "Epoch 197/200\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.8260\n",
            "Epoch 198/200\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8238\n",
            "Epoch 199/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8193\n",
            "Epoch 200/200\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8272\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "output=model.fit(X_train,Y_train,epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NtmaBbynm8jq",
        "outputId": "1c205987-4cda-4a73-839a-64e708196b1b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['accuracy'])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'accuracy'], loc='upper right')\n",
        "plt.title('MLP algorithm for Titanic problem')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qtEuNgCnzhy",
        "outputId": "86126735-450e-4a7b-feee-3a3cdc261009"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/parisa/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save('titanic.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=tf.keras.models.load_model('titanic.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j8aYBS_po0s",
        "outputId": "fee53dbf-357f-4724-fd2e-047aa28d2b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8708\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.34846705198287964, 0.8708133697509766]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "model.evaluate(X_test,Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB9k2ZpqvnQF",
        "outputId": "c4d06f19-f3eb-41e7-dd16-d4c34b9a98b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 123ms/step\n",
            "Survived\n"
          ]
        }
      ],
      "source": [
        "#predict if the passenger survived\n",
        "pred=[[2,0,34,0,1,54.3900,2]]\n",
        "y_pred=np.argmax(model.predict(pred))\n",
        "if y_pred==1:\n",
        "  print('Survived')\n",
        "else:\n",
        "    print('Not Survived')  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = Dense(6, activation = \"relu\")\n",
        "        self.d2 = Dense(16, activation = \"relu\")\n",
        "        self.d3 = Dense(2 ,activation = \"softmax\")\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        x = self.d3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train(X_train, Y_train):\n",
        "  with tf.GradientTape() as tape:\n",
        "      pred = model(X_train)\n",
        "      loss = loss_function(Y_train, pred)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_accuracy(Y_train, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test(X_test, Y_test):\n",
        "  pred = model(X_test)\n",
        "  loss = loss_function(Y_test, pred)\n",
        "  test_loss(loss)\n",
        "  test_accuracy(Y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/parisa/.local/lib/python3.10/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n",
            "  2%|         | 1/50 [00:02<02:26,  2.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 , Train Loss : 1.176470398902893 , Train Acuuracy : 0.5140292048454285 , Test Loss : 0.6413077712059021 , Test Accuracy : 0.6363636255264282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|         | 2/50 [00:03<01:11,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 , Train Loss : 0.6228109002113342 , Train Acuuracy : 0.650954008102417 , Test Loss : 0.6124295592308044 , Test Accuracy : 0.6483253836631775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|         | 3/50 [00:03<00:45,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 , Train Loss : 0.5919656753540039 , Train Acuuracy : 0.683501660823822 , Test Loss : 0.6121317148208618 , Test Accuracy : 0.6578947305679321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|         | 4/50 [00:04<00:32,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 , Train Loss : 0.5850586891174316 , Train Acuuracy : 0.6879910230636597 , Test Loss : 0.6308020353317261 , Test Accuracy : 0.6507176756858826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|         | 5/50 [00:04<00:25,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 , Train Loss : 0.5888320207595825 , Train Acuuracy : 0.6936026811599731 , Test Loss : 0.5966229438781738 , Test Accuracy : 0.6626794338226318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|        | 6/50 [00:04<00:23,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 , Train Loss : 0.5775560736656189 , Train Acuuracy : 0.7037037014961243 , Test Loss : 0.5906170606613159 , Test Accuracy : 0.6889952421188354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|        | 7/50 [00:05<00:21,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7 , Train Loss : 0.5740108489990234 , Train Acuuracy : 0.7014590501785278 , Test Loss : 0.5851025581359863 , Test Accuracy : 0.6842105388641357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|        | 8/50 [00:05<00:19,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 8 , Train Loss : 0.5688415765762329 , Train Acuuracy : 0.6992143392562866 , Test Loss : 0.5771875381469727 , Test Accuracy : 0.6889952421188354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|        | 9/50 [00:06<00:18,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9 , Train Loss : 0.5654348731040955 , Train Acuuracy : 0.7025813460350037 , Test Loss : 0.5698189735412598 , Test Accuracy : 0.6913875341415405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|        | 10/50 [00:06<00:16,  2.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 10 , Train Loss : 0.5623764395713806 , Train Acuuracy : 0.7025813460350037 , Test Loss : 0.564181387424469 , Test Accuracy : 0.6937798857688904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|       | 11/50 [00:06<00:14,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 11 , Train Loss : 0.5602074861526489 , Train Acuuracy : 0.7070707082748413 , Test Loss : 0.5563353896141052 , Test Accuracy : 0.6985645890235901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|       | 12/50 [00:07<00:13,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 12 , Train Loss : 0.5597568154335022 , Train Acuuracy : 0.7070707082748413 , Test Loss : 0.5504640340805054 , Test Accuracy : 0.7009569406509399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|       | 13/50 [00:07<00:13,  2.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 13 , Train Loss : 0.5547647476196289 , Train Acuuracy : 0.7093153595924377 , Test Loss : 0.5449001789093018 , Test Accuracy : 0.7009569406509399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|       | 14/50 [00:07<00:12,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 14 , Train Loss : 0.5526461601257324 , Train Acuuracy : 0.7126823663711548 , Test Loss : 0.5389954447746277 , Test Accuracy : 0.7009569406509399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|       | 15/50 [00:07<00:11,  3.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 15 , Train Loss : 0.5481607913970947 , Train Acuuracy : 0.7104377150535583 , Test Loss : 0.5321874618530273 , Test Accuracy : 0.7009569406509399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|      | 16/50 [00:08<00:10,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 16 , Train Loss : 0.5434747934341431 , Train Acuuracy : 0.7160493731498718 , Test Loss : 0.5246148109436035 , Test Accuracy : 0.7057416439056396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|      | 17/50 [00:08<00:10,  3.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 17 , Train Loss : 0.54022616147995 , Train Acuuracy : 0.7205387353897095 , Test Loss : 0.5170327425003052 , Test Accuracy : 0.7129186391830444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|      | 18/50 [00:08<00:10,  2.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 18 , Train Loss : 0.5348743200302124 , Train Acuuracy : 0.7373737096786499 , Test Loss : 0.5052267909049988 , Test Accuracy : 0.720095694065094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|      | 19/50 [00:09<00:11,  2.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 19 , Train Loss : 0.5271349549293518 , Train Acuuracy : 0.7340067625045776 , Test Loss : 0.49717506766319275 , Test Accuracy : 0.7272727489471436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|      | 20/50 [00:10<00:13,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 20 , Train Loss : 0.5238837599754333 , Train Acuuracy : 0.7340067625045776 , Test Loss : 0.4852220416069031 , Test Accuracy : 0.7344497442245483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|     | 21/50 [00:10<00:13,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 21 , Train Loss : 0.5166186094284058 , Train Acuuracy : 0.7418630719184875 , Test Loss : 0.47197139263153076 , Test Accuracy : 0.7416267991065979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|     | 22/50 [00:11<00:13,  2.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 22 , Train Loss : 0.5113650560379028 , Train Acuuracy : 0.7463524341583252 , Test Loss : 0.45770615339279175 , Test Accuracy : 0.7440191507339478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|     | 23/50 [00:11<00:11,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 23 , Train Loss : 0.5062711834907532 , Train Acuuracy : 0.7586981058120728 , Test Loss : 0.4466407597064972 , Test Accuracy : 0.7703348994255066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|     | 24/50 [00:11<00:10,  2.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 24 , Train Loss : 0.49914318323135376 , Train Acuuracy : 0.7766554355621338 , Test Loss : 0.43231096863746643 , Test Accuracy : 0.7942583560943604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|     | 25/50 [00:11<00:08,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 25 , Train Loss : 0.49614766240119934 , Train Acuuracy : 0.7777777910232544 , Test Loss : 0.4220157861709595 , Test Accuracy : 0.8038277626037598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|    | 26/50 [00:12<00:08,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 26 , Train Loss : 0.4881722331047058 , Train Acuuracy : 0.7833894491195679 , Test Loss : 0.4090782701969147 , Test Accuracy : 0.8301435112953186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|    | 27/50 [00:12<00:07,  3.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 27 , Train Loss : 0.4882538914680481 , Train Acuuracy : 0.7856341004371643 , Test Loss : 0.39271342754364014 , Test Accuracy : 0.8421052694320679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|    | 28/50 [00:12<00:07,  3.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 28 , Train Loss : 0.4833703935146332 , Train Acuuracy : 0.7912458181381226 , Test Loss : 0.3763805031776428 , Test Accuracy : 0.8612440228462219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|    | 29/50 [00:13<00:06,  3.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 29 , Train Loss : 0.4769222140312195 , Train Acuuracy : 0.793490469455719 , Test Loss : 0.35189875960350037 , Test Accuracy : 0.9043062329292297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|    | 30/50 [00:13<00:06,  3.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 30 , Train Loss : 0.46997880935668945 , Train Acuuracy : 0.7991021275520325 , Test Loss : 0.3458148241043091 , Test Accuracy : 0.9043062329292297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|   | 31/50 [00:13<00:05,  3.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 31 , Train Loss : 0.4691270887851715 , Train Acuuracy : 0.793490469455719 , Test Loss : 0.33477938175201416 , Test Accuracy : 0.9114832282066345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|   | 32/50 [00:14<00:05,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 32 , Train Loss : 0.46661415696144104 , Train Acuuracy : 0.8002244830131531 , Test Loss : 0.32027187943458557 , Test Accuracy : 0.9210526347160339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|   | 33/50 [00:14<00:05,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 33 , Train Loss : 0.46324220299720764 , Train Acuuracy : 0.8024691343307495 , Test Loss : 0.3027147650718689 , Test Accuracy : 0.9234449863433838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|   | 34/50 [00:14<00:05,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 34 , Train Loss : 0.4533819556236267 , Train Acuuracy : 0.804713785648346 , Test Loss : 0.29775184392929077 , Test Accuracy : 0.9186602830886841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|   | 35/50 [00:15<00:04,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 35 , Train Loss : 0.4552862048149109 , Train Acuuracy : 0.8058361411094666 , Test Loss : 0.2953506410121918 , Test Accuracy : 0.9258373379707336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|  | 36/50 [00:15<00:04,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 36 , Train Loss : 0.45491155982017517 , Train Acuuracy : 0.8058361411094666 , Test Loss : 0.2861206829547882 , Test Accuracy : 0.9306219816207886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|  | 37/50 [00:15<00:04,  3.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 37 , Train Loss : 0.45274361968040466 , Train Acuuracy : 0.7957351207733154 , Test Loss : 0.27711930871009827 , Test Accuracy : 0.940191388130188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|  | 38/50 [00:16<00:04,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 38 , Train Loss : 0.44819387793540955 , Train Acuuracy : 0.8024691343307495 , Test Loss : 0.2776050865650177 , Test Accuracy : 0.9306219816207886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|  | 39/50 [00:16<00:03,  2.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 39 , Train Loss : 0.4495551288127899 , Train Acuuracy : 0.7946127653121948 , Test Loss : 0.2723633348941803 , Test Accuracy : 0.9521530866622925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|  | 40/50 [00:16<00:03,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 40 , Train Loss : 0.4481872618198395 , Train Acuuracy : 0.793490469455719 , Test Loss : 0.2677950859069824 , Test Accuracy : 0.9449760913848877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%| | 41/50 [00:17<00:03,  2.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 41 , Train Loss : 0.4456629157066345 , Train Acuuracy : 0.793490469455719 , Test Loss : 0.26661354303359985 , Test Accuracy : 0.9497607946395874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%| | 42/50 [00:17<00:03,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 42 , Train Loss : 0.44544363021850586 , Train Acuuracy : 0.7923681139945984 , Test Loss : 0.2613750696182251 , Test Accuracy : 0.9473684430122375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%| | 43/50 [00:18<00:02,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 43 , Train Loss : 0.44540801644325256 , Train Acuuracy : 0.793490469455719 , Test Loss : 0.26639267802238464 , Test Accuracy : 0.9521530866622925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%| | 44/50 [00:18<00:02,  2.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 44 , Train Loss : 0.4452325999736786 , Train Acuuracy : 0.7923681139945984 , Test Loss : 0.26200371980667114 , Test Accuracy : 0.9545454382896423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%| | 45/50 [00:19<00:02,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 45 , Train Loss : 0.4422440528869629 , Train Acuuracy : 0.7912458181381226 , Test Loss : 0.2591383159160614 , Test Accuracy : 0.9473684430122375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|| 46/50 [00:19<00:01,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 46 , Train Loss : 0.44126978516578674 , Train Acuuracy : 0.7923681139945984 , Test Loss : 0.2549543082714081 , Test Accuracy : 0.9473684430122375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|| 47/50 [00:19<00:01,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 47 , Train Loss : 0.4446369707584381 , Train Acuuracy : 0.7923681139945984 , Test Loss : 0.25690677762031555 , Test Accuracy : 0.940191388130188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|| 48/50 [00:20<00:01,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 48 , Train Loss : 0.44223690032958984 , Train Acuuracy : 0.7923681139945984 , Test Loss : 0.25366833806037903 , Test Accuracy : 0.9449760913848877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|| 49/50 [00:21<00:00,  2.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 49 , Train Loss : 0.4433026909828186 , Train Acuuracy : 0.7923681139945984 , Test Loss : 0.25513559579849243 , Test Accuracy : 0.9425837397575378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 50/50 [00:21<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 50 , Train Loss : 0.44032758474349976 , Train Acuuracy : 0.7946127653121948 , Test Loss : 0.25250768661499023 , Test Accuracy : 0.9473684430122375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  #train\n",
        "  for X_train, Y_train in train_dataset:\n",
        "    train(X_train, Y_train)\n",
        "\n",
        "\n",
        "  #test\n",
        "  for X_test,Y_test in test_dataset:\n",
        "    test(X_test, Y_test)\n",
        "\n",
        "  print(f\"Epoch : {epoch+1} , Train Loss : {train_loss.result()} , Train Acuuracy : {train_accuracy.result()} , Test Loss : {test_loss.result()} , Test Accuracy : {test_accuracy.result()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"titanic_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"titanic_model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Titanic_Tensorflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
