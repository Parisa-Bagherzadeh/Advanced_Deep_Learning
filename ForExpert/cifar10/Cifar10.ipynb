{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HLc3ioaoLa30"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWqcrX5pNC3B",
        "outputId": "4729fa6d-7c0c-4be6-cacb-a0d8a0c97c72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh6llV_kFctM",
        "outputId": "3c6d8ca1-d9ce-4656-c986-8208fa46bc1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "swA6XctoFe3u"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(1000).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KB_61VERFga4"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = Conv2D(32, (3,3), activation = \"relu\")\n",
        "    self.b1 = BatchNormalization()\n",
        "    self.conv2 = Conv2D(32, (3, 3), activation = \"relu\")\n",
        "    self.b2 = BatchNormalization()\n",
        "    self.maxpool1 = MaxPooling2D(2,2)\n",
        "    self.dropout1 = Dropout(0.2)\n",
        "\n",
        "    self.conv3 = Conv2D(64,(3, 3), activation='relu', kernel_initializer ='he_uniform', padding='same')\n",
        "    self.b3 = BatchNormalization()\n",
        "    self.conv4 = Conv2D(64,(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')\n",
        "    self.b4 = BatchNormalization()\n",
        "    self.maxpool2 = MaxPooling2D(2, 2)\n",
        "    self.dropout2 = Dropout(0.3)\n",
        "\n",
        "    self.conv5 = Conv2D(128,(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')\n",
        "    self.b5 = BatchNormalization()\n",
        "    self.conv6 = Conv2D(128,(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')\n",
        "    self.b6 = BatchNormalization()\n",
        "    self.maxpool3 = MaxPooling2D(2, 2)\n",
        "    self.dropout3 = Dropout(0.4)\n",
        "\n",
        "\n",
        "    self.f = Flatten()\n",
        "    self.d1 = Dense(128,activation = 'relu')\n",
        "    self.b7 = BatchNormalization()\n",
        "    self.dropout4 = Dropout(0.5)\n",
        "    self.d2 = Dense(10,activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.b1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.b2(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.dropout1(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.b3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.b4(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.b5(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.b6(x)\n",
        "    x = self.maxpool3(x)\n",
        "    x = self.dropout3(x)\n",
        "    x = self.f(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.b7(x)\n",
        "    x = self.dropout4(x)\n",
        "    x = self.d2(x)\n",
        "    return x\n",
        "\n",
        "model = MyModel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "57CTb1CcFiFO"
      },
      "outputs": [],
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-MQTYr7NFj04"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JMZnFanFFlUG"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "      pred = model(images)\n",
        "      loss = loss_function(labels, pred)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xJvCvaENFmn6"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test(images, labels):\n",
        "  pred = model(images)\n",
        "  loss = loss_function(labels, pred)\n",
        "  test_loss(loss)\n",
        "  test_accuracy(labels, pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Tct1qJFoWS",
        "outputId": "122c8f94-ffb0-4be3-848d-897bc810d44b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n",
            " 10%|█         | 1/10 [00:18<02:43, 18.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 , Train Loss : 1.3395527601242065 , Train Acuuracy : 0.514680027961731 , Test Loss : 0.983324408531189 , Test Accuracy : 0.6539000272750854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:27<01:43, 12.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 , Train Loss : 0.8087024688720703 , Train Acuuracy : 0.7171000242233276 , Test Loss : 0.8205610513687134 , Test Accuracy : 0.7186999917030334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:36<01:17, 11.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 , Train Loss : 0.6026347279548645 , Train Acuuracy : 0.787880003452301 , Test Loss : 0.7271824479103088 , Test Accuracy : 0.7577000260353088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:45<01:01, 10.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 , Train Loss : 0.46835657954216003 , Train Acuuracy : 0.8374599814414978 , Test Loss : 0.7781147360801697 , Test Accuracy : 0.7595000267028809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:54<00:48,  9.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 , Train Loss : 0.3695261776447296 , Train Acuuracy : 0.8705199956893921 , Test Loss : 0.8057472109794617 , Test Accuracy : 0.7621999979019165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:03<00:38,  9.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 , Train Loss : 0.28793326020240784 , Train Acuuracy : 0.8972600102424622 , Test Loss : 0.9143120050430298 , Test Accuracy : 0.7638999819755554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [01:12<00:28,  9.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7 , Train Loss : 0.23540222644805908 , Train Acuuracy : 0.9171800017356873 , Test Loss : 0.9234941005706787 , Test Accuracy : 0.7730000019073486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:21<00:18,  9.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 8 , Train Loss : 0.2082156389951706 , Train Acuuracy : 0.9261999726295471 , Test Loss : 1.0179146528244019 , Test Accuracy : 0.7674999833106995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:29<00:09,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9 , Train Loss : 0.17695429921150208 , Train Acuuracy : 0.9378600120544434 , Test Loss : 1.038375973701477 , Test Accuracy : 0.76910001039505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:40<00:00, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 10 , Train Loss : 0.161626935005188 , Train Acuuracy : 0.9437599778175354 , Test Loss : 1.1030232906341553 , Test Accuracy : 0.7663999795913696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  #train\n",
        "  for images, labels in train_dataset:\n",
        "    train(images, labels)\n",
        "\n",
        "\n",
        "  #test\n",
        "  for images,labels in test_dataset:\n",
        "    test(images, labels)\n",
        "\n",
        "  print(f\"Epoch : {epoch+1} , Train Loss : {train_loss.result()} , Train Acuuracy : {train_accuracy.result()} , Test Loss : {test_loss.result()} , Test Accuracy : {test_accuracy.result()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZMOdJl3Fp_t",
        "outputId": "47a1d456-b843-47a0-be47-7821bdb8b010"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "labels = [\"airplane\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\",\"trucks\"]\n",
        "\n",
        "image = cv2.imread(\"/content/airplane.jpeg\")\n",
        "image = cv2.resize(image, (32, 32))\n",
        "image = image[tf.newaxis, ...]\n",
        "image = image.astype(\"float32\")\n",
        "image.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AFym7oYuaY9n",
        "outputId": "17dd0910-445f-4e1a-fa6d-67b2a46874eb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'airplane'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = model(image)\n",
        "result = np.argmax(pred)\n",
        "label = labels[result]\n",
        "label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "i-QFMJJUZcyS"
      },
      "outputs": [],
      "source": [
        "model.save(\"cifar10_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa9DJmbLZgQi",
        "outputId": "48b55933-9691-46b7-fd20-2b1384c5749c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"cifar10_model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
